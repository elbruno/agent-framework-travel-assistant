# AI Travel Concierge Configuration
# Copy this file to .env and fill in your actual values
# This file mirrors variables defined in config.AppConfig (required + defaults)

# Core provider selection
LLM_PROVIDER=openai # or azure_openai
SEARCH_PROVIDER=tavily # or azure_foundry_agent

# OpenAI configuration (required when LLM_PROVIDER=openai)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Azure OpenAI configuration (required when LLM_PROVIDER=azure_openai)
# AZURE_OPENAI_API_KEY=
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_API_VERSION=2024-10-21
# AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME=travel-agent
# AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME=mem0-embeddings
# AZURE_OPENAI_MEM0_LLM_DEPLOYMENT_NAME=mem0-llm

# Search configuration
# Tavily (when SEARCH_PROVIDER=tavily)
TAVILY_API_KEY=your-tavily-api-key-here

# Azure AI Foundry Search Agent (when SEARCH_PROVIDER=azure_foundry_agent)
# AZURE_FOUNDRY_API_KEY=your-foundry-api-key
# AZURE_FOUNDRY_ENDPOINT=https://your-foundry-endpoint.azure.com/invoke
# AZURE_FOUNDRY_SEARCH_AGENT_ID=your-search-agent-id

MEM0_API_KEY=your-mem0-api-key

# Optional Model Configuration (leave unset to use these defaults)
TRAVEL_AGENT_MODEL=gpt-4o-mini
MEM0_CLOUD=false # If using Mem0 Cloud, set true, and provide your Mem0 API key 
MEM0_MODEL=gpt-4o-mini
MEM0_EMBEDDING_MODEL=text-embedding-3-small
MEM0_EMBEDDING_MODEL_DIMS=1536

MAX_TOOL_ITERATIONS=8

# Optional Redis Configuration (leave unset to use these defaults)
REDIS_URL=redis://localhost:6379

# Optional Server Configuration (leave unset to use these defaults)
SERVER_NAME=0.0.0.0
SERVER_PORT=7860
SHARE=false

MAX_CHAT_HISTORY_SIZE=6
MAX_SEARCH_RESULTS=5